{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":22881,"databundleVersionId":1552852,"sourceType":"competition"},{"sourceId":465507,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":370203,"modelId":391090}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2,MobileNetV3Small,EfficientNetV2B0\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nimport pandas as pd\nimport numpy as np\nimport os\nimport datetime\nfrom sklearn.metrics import roc_curve, auc\nimport cv2\nfrom tensorflow.keras.mixed_precision import set_global_policy, Policy\n\n# # Enable memory growth for both T4 GPUs\n# gpus = tf.config.list_physical_devices('GPU')\n# print(\"Available GPUs:\", [gpu.name for gpu in gpus])  # Should list two T4 GPUs\n# for gpu in gpus:\n#     tf.config.experimental.set_memory_growth(gpu, True)\n\n\n\n# Initialize MirroredStrategy\nstrategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\nprint(\"Number of GPUs in strategy:\", strategy.num_replicas_in_sync)  # Should print 2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:49:17.575625Z","iopub.execute_input":"2025-07-09T10:49:17.575833Z","iopub.status.idle":"2025-07-09T10:49:32.041716Z","shell.execute_reply.started":"2025-07-09T10:49:17.575812Z","shell.execute_reply":"2025-07-09T10:49:32.040983Z"}},"outputs":[{"name":"stderr","text":"2025-07-09 10:49:19.120928: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752058159.316731      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752058159.371356      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Number of GPUs in strategy: 2\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752058172.006912      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"IMG_SIZE = (112, 112)\nBATCH_SIZE = 128\nEPOCHS = 20\n\ndata_dir = \"/kaggle/input/11-785-fall-20-homework-2-part-2\"\npairs_file = os.path.join(data_dir, \"verification_pairs_val.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:49:32.043137Z","iopub.execute_input":"2025-07-09T10:49:32.043602Z","iopub.status.idle":"2025-07-09T10:49:32.047756Z","shell.execute_reply.started":"2025-07-09T10:49:32.043582Z","shell.execute_reply":"2025-07-09T10:49:32.046992Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\ndef create_data_generators(data_dir):\n\n\n    # Define data augmentation for training\n    train_datagen = ImageDataGenerator(\n      \n        zoom_range = 0.3,\n        shear_range = 0.2,        \n        fill_mode=\"nearest\",\n        horizontal_flip=True\n    )\n\n    # Define validation data generator (no augmentation, only rescaling)\n    val_datagen = ImageDataGenerator()\n\n    # Classification data generator for training\n    train_generator = train_datagen.flow_from_directory(\n        os.path.join(data_dir, 'classification_data/train_data'),\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        color_mode = 'rgb',\n        class_mode='categorical',\n        shuffle = True \n    )\n\n    # Classification data generator for validation\n    val_generator = val_datagen.flow_from_directory(\n        os.path.join(data_dir, 'classification_data/val_data'),\n        target_size=IMG_SIZE,\n        color_mode = 'rgb',\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle = False\n    )\n\n    \n\n    # Return datasets and number of classes\n    return train_generator, val_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:49:32.048463Z","iopub.execute_input":"2025-07-09T10:49:32.048710Z","iopub.status.idle":"2025-07-09T10:49:32.134645Z","shell.execute_reply.started":"2025-07-09T10:49:32.048695Z","shell.execute_reply":"2025-07-09T10:49:32.134055Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\ntrain_dataset, val_dataset = create_data_generators(data_dir)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:49:32.135386Z","iopub.execute_input":"2025-07-09T10:49:32.135606Z","iopub.status.idle":"2025-07-09T10:56:45.294850Z","shell.execute_reply.started":"2025-07-09T10:49:32.135589Z","shell.execute_reply":"2025-07-09T10:56:45.294159Z"}},"outputs":[{"name":"stdout","text":"Found 380638 images belonging to 4000 classes.\nFound 8000 images belonging to 4000 classes.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def create_verification_generator(data_dir, pairs_file):\n    df = pd.read_csv(pairs_file, sep='\\s+', names=['img1', 'img2', 'label'])\n    \n    def generator():\n        for _, row in df.iterrows():\n            img1 = cv2.imread(os.path.join(data_dir, row['img1']))\n            img2 = cv2.imread(os.path.join(data_dir, row['img2']))\n            img1 = cv2.resize(img1, IMG_SIZE) / 255.0  # Hardcode the size\n            img2 = cv2.resize(img2, IMG_SIZE) / 255.0\n            yield [img1, img2], row['label']\n    \n    # Use output_signature instead of output_types/output_shapes\n    dataset = tf.data.Dataset.from_generator(\n        generator,\n        output_signature=(\n            (tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), dtype=tf.float32),\n             tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), dtype=tf.float32)),\n            tf.TensorSpec(shape=(), dtype=tf.float32)\n        )\n    )\n    \n    return dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:56:45.295656Z","iopub.execute_input":"2025-07-09T10:56:45.295997Z","iopub.status.idle":"2025-07-09T10:56:45.301989Z","shell.execute_reply.started":"2025-07-09T10:56:45.295972Z","shell.execute_reply":"2025-07-09T10:56:45.301169Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"verification_dataset = create_verification_generator(data_dir, pairs_file)\nprint(len(train_dataset.class_indices))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:56:45.302590Z","iopub.execute_input":"2025-07-09T10:56:45.302777Z","iopub.status.idle":"2025-07-09T10:56:45.419467Z","shell.execute_reply.started":"2025-07-09T10:56:45.302762Z","shell.execute_reply":"2025-07-09T10:56:45.418927Z"}},"outputs":[{"name":"stdout","text":"4000\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def create_siamese_network(input_shape =(*IMG_SIZE, 3)):\n    base_model = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = input_shape)\n\n    for layer in base_model.layers:\n        layer.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128, activation = None, name = 'embedding')(x)\n    base_network = Model(inputs = base_model.input, outputs = x)\n    input_a = Input(shape = input_shape)\n    input_b = Input(shape = input_shape)\n\n    embedding_a = base_network(input_a)\n    embedding_b = base_network(input_b)\n\n    # Calculate Euclidean distance\n    distance = Lambda(lambda tensors: tf.sqrt(tf.reduce_sum(tf.square(tensors[0] - tensors[1]), axis=1, keepdims=True)))([embedding_a, embedding_b])\n    \n    # Create Siamese model\n    siamese_model = Model(inputs=[input_a, input_b], outputs=distance)\n    \n    return siamese_model, base_network\n\n\ndef create_classification_model(num_classes, input_shape =(*IMG_SIZE, 3)):\n    base_model = EfficientNetV2B0(weights = 'imagenet', include_top = False, input_shape= input_shape)\n    base_model.trainable = True\n\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    \n    x = Dense(128)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.4)(x)\n    \n    output = Dense(num_classes, activation = 'softmax')(x)\n\n    model = Model(inputs = base_model.input, outputs = output)\n    return model, base_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:56:45.421096Z","iopub.execute_input":"2025-07-09T10:56:45.421288Z","iopub.status.idle":"2025-07-09T10:56:45.427814Z","shell.execute_reply.started":"2025-07-09T10:56:45.421273Z","shell.execute_reply":"2025-07-09T10:56:45.427134Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def create_callbacks(model_name):\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_accuracy',\n        factor=0.1,\n        patience=4,\n        min_lr=1e-6,\n        verbose=1\n    )\n    \n    early_stopping = EarlyStopping(\n        monitor='val_accuracy',\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    )\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    checkpoint = ModelCheckpoint(\n        f'best_{model_name}_model_{timestamp}.keras',\n        monitor='val_accuracy',\n        save_best_only=True,\n        mode= 'auto',\n        verbose=1\n    )\n    \n    return [reduce_lr, early_stopping, checkpoint]\n    \ndef train_classification_model(pretrained_model_path=None, initial_epoch=0, phase=None):\n\n    classification_model, base_model = create_classification_model(\n        len(train_dataset.class_indices), (*IMG_SIZE, 3)\n    )\n    \n    # If you have a pretrained model, load weights instead\n    if pretrained_model_path:\n        classification_model = load_model(pretrained_model_path)\n    \n    # Compile\n    classification_model.compile(\n        optimizer=Adam(learning_rate=0.0001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    classification_callbacks = create_callbacks(\"EfficientNetV2B0_classification\")\n    history_phase1 = None\n    if phase in [1, None]:\n        # Phase 1: Frozen base model training\n        history_phase1 = classification_model.fit(\n            train_dataset,\n            validation_data=val_dataset,\n            epochs=EPOCHS,\n            initial_epoch=initial_epoch,\n            verbose=1,\n            callbacks=classification_callbacks\n        )\n\n    # Phase 2: Fine-tuning\n    for layer in classification_model.layers:\n        layer.trainable = True\n    print(f\"Unfroze base model: {base_model.name}\")\n    fine_tune_epoch = initial_epoch if phase == 2 else EPOCHS\n\n    \n    \n    classification_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    # Fine-tuning phase\n    history_phase2 = classification_model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=100,\n        initial_epoch=fine_tune_epoch,\n        verbose=1,\n        callbacks=create_callbacks(\"classification_finetuned\")\n    )\n\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    print(f\"Saving model at {timestamp}\")\n    classification_model.save(f\"custom_model_{timestamp}.keras\")\n    df = pd.DataFrame(history_phase2.history)\n    df.to_csv(f\"custom_model_loss_{timestamp}.csv\")\n\n    return classification_model, history_phase1, history_phase2\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:56:45.428520Z","iopub.execute_input":"2025-07-09T10:56:45.428714Z","iopub.status.idle":"2025-07-09T10:56:45.442079Z","shell.execute_reply.started":"2025-07-09T10:56:45.428697Z","shell.execute_reply":"2025-07-09T10:56:45.441391Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def contrastive_loss(y_true, y_pred):\n    \"\"\"Simple contrastive loss for Siamese network.\"\"\"\n    margin = 1.0\n    square_pred = tf.square(y_pred)\n    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n\ndef train_siamese_model(model=None, base_model=None, initial_epoch=0, phase=None):\n    global strategy  # Use the global MirroredStrategy from Step 1\n\n    \n    if model is None:\n        siamese_model, base_network = create_siamese_network((*IMG_SIZE, 3))\n    else:\n        siamese_model = model\n        base_network = base_model if base_model else siamese_model.get_layer('model')  # Extract base network\n\n    # Compile model\n    siamese_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4, weight_decay=1e-4),\n        loss=contrastive_loss,\n        metrics=['accuracy']\n    )\n\n    siamese_callbacks = create_callbacks(\"siamese\")\n    history_phase1 = None\n    if phase in [None, 1]:\n        print(\"=== Phase 1: Training Siamese Model (Frozen Base) ===\")\n        history_phase1 = siamese_model.fit(\n            verification_dataset,\n            validation_data=verification_dataset,  # Replace with actual validation dataset if available\n            epochs=EPOCHS,\n            initial_epoch=initial_epoch,\n            verbose=1,\n            callbacks=siamese_callbacks\n        )\n\n    # Phase 2: Fine-tuning\n    for layer in base_network.layers:\n        layer.trainable = True\n        print(f\"Unfroze layer: {layer.name}\")\n\n    # Recompile with lower learning rate\n    \n    siamese_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n        loss=contrastive_loss,\n        metrics=['accuracy']\n    )\n\n    \n    history_phase2 = siamese_model.fit(\n        verification_dataset,\n        validation_data=verification_dataset,  # Replace with actual validation dataset if available\n        epochs=EPOCHS,\n        initial_epoch=initial_epoch if phase == 1 else EPOCHS,\n        verbose=1,\n        callbacks=create_callbacks(\"siamese_finetuned\")\n    )\n\n    print(\"Saving model\")\n    siamese_model.save(\"custom_model_siamese.keras\")\n    df = pd.DataFrame(history_phase2.history)\n    df.to_csv(\"custom_model_siamese_loss.csv\")\n\n    return siamese_model, base_network, history_phase1, history_phase2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:56:45.442668Z","iopub.execute_input":"2025-07-09T10:56:45.442856Z","iopub.status.idle":"2025-07-09T10:56:45.460623Z","shell.execute_reply.started":"2025-07-09T10:56:45.442840Z","shell.execute_reply":"2025-07-09T10:56:45.460083Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def evaluate_model(siamese_model, verification_dataset):\n    predictions = []\n    true_labels = []\n\n    for (img1, img2), label in verification_dataset:\n        pred = siamese_model.predict([img1, img2], verbose=0)\n        predictions.extend(pred.flatten())\n        true_labels.extend(label.numpy())\n\n    fpr, tpr, _ = roc_curve(true_labels, predictions)\n    roc_auc = auc(fpr, tpr)\n\n    return fpr, tpr, roc_auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:56:45.461311Z","iopub.execute_input":"2025-07-09T10:56:45.461562Z","iopub.status.idle":"2025-07-09T10:56:45.480861Z","shell.execute_reply.started":"2025-07-09T10:56:45.461542Z","shell.execute_reply":"2025-07-09T10:56:45.480275Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def main():\n    # Load or create classification model\n    classification_model, hist1, hist2 = train_classification_model(\n        pretrained_model_path=\"/kaggle/input/face_verfication_models/keras/default/11/best_classification_finetuned_model_20250709_015900.keras\",\n        initial_epoch=81,\n        phase=2\n    )\n\n    # Train Siamese model\n    siamese_model, base_network, siamese_hist1, siamese_hist2 = train_siamese_model(\n        initial_epoch=0,\n        phase=None\n    )\n\n    # Evaluate Siamese model\n    verification_dataset = create_verification_generator(data_dir, pairs_file)\n    fpr, tpr, roc_auc = evaluate_model(siamese_model, verification_dataset)\n    print(f\"ROC AUC: {roc_auc}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T10:56:45.481428Z","iopub.execute_input":"2025-07-09T10:56:45.481654Z","execution_failed":"2025-07-09T15:30:56.069Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nUnfroze base model: efficientnetv2-b0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 82/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1752058681.260095      94 service.cc:148] XLA service 0x7afcc80034a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1752058681.260846      94 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1752058687.074227      94 cuda_dnn.cc:529] Loaded cuDNN version 90300\nE0000 00:00:1752058696.627475      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752058696.814997      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752058697.356584      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752058697.570167      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/2974\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m85:24:14\u001b[0m 103s/step - accuracy: 0.8125 - loss: 0.8195","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752058718.509073      94 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2927/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:12\u001b[0m 2s/step - accuracy: 0.7649 - loss: 0.9397","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1752063235.030733      92 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752063235.216051      92 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752063235.692784      92 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752063235.902047      92 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7648 - loss: 0.9399\nEpoch 82: val_accuracy improved from -inf to 0.71887, saving model to best_classification_finetuned_model_20250709_105651.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4772s\u001b[0m 2s/step - accuracy: 0.7648 - loss: 0.9399 - val_accuracy: 0.7189 - val_loss: 1.4996 - learning_rate: 1.0000e-04\nEpoch 83/100\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step - accuracy: 0.7694 - loss: 0.9173\nEpoch 83: val_accuracy improved from 0.71887 to 0.71987, saving model to best_classification_finetuned_model_20250709_105651.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1873s\u001b[0m 630ms/step - accuracy: 0.7694 - loss: 0.9173 - val_accuracy: 0.7199 - val_loss: 1.4919 - learning_rate: 1.0000e-04\nEpoch 84/100\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step - accuracy: 0.7721 - loss: 0.9108\nEpoch 84: val_accuracy improved from 0.71987 to 0.72075, saving model to best_classification_finetuned_model_20250709_105651.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1806s\u001b[0m 607ms/step - accuracy: 0.7721 - loss: 0.9108 - val_accuracy: 0.7207 - val_loss: 1.4823 - learning_rate: 1.0000e-04\nEpoch 85/100\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611ms/step - accuracy: 0.7725 - loss: 0.8991\nEpoch 85: val_accuracy improved from 0.72075 to 0.72225, saving model to best_classification_finetuned_model_20250709_105651.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1836s\u001b[0m 617ms/step - accuracy: 0.7725 - loss: 0.8991 - val_accuracy: 0.7222 - val_loss: 1.4957 - learning_rate: 1.0000e-04\nEpoch 86/100\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.7766 - loss: 0.8827\nEpoch 86: val_accuracy improved from 0.72225 to 0.72287, saving model to best_classification_finetuned_model_20250709_105651.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1826s\u001b[0m 614ms/step - accuracy: 0.7766 - loss: 0.8827 - val_accuracy: 0.7229 - val_loss: 1.4679 - learning_rate: 1.0000e-04\nEpoch 87/100\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.7778 - loss: 0.8772\nEpoch 87: val_accuracy improved from 0.72287 to 0.72725, saving model to best_classification_finetuned_model_20250709_105651.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1817s\u001b[0m 611ms/step - accuracy: 0.7778 - loss: 0.8772 - val_accuracy: 0.7272 - val_loss: 1.4841 - learning_rate: 1.0000e-04\nEpoch 88/100\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step - accuracy: 0.7815 - loss: 0.8625\nEpoch 88: val_accuracy did not improve from 0.72725\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1843s\u001b[0m 620ms/step - accuracy: 0.7815 - loss: 0.8626 - val_accuracy: 0.7243 - val_loss: 1.5065 - learning_rate: 1.0000e-04\nEpoch 89/100\n\u001b[1m1191/2974\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m16:40\u001b[0m 561ms/step - accuracy: 0.7858 - loss: 0.8359","output_type":"stream"}],"execution_count":null}]}