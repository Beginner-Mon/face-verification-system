{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":22881,"databundleVersionId":1552852,"sourceType":"competition"},{"sourceId":472514,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":376149,"modelId":396863}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2,MobileNetV3Small,EfficientNetV2B0\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nimport pandas as pd\nimport numpy as np\nimport os\nimport datetime\nfrom sklearn.metrics import roc_curve, auc\nimport cv2\nfrom tensorflow.keras.mixed_precision import set_global_policy, Policy\n\n# # Enable memory growth for both T4 GPUs\n# gpus = tf.config.list_physical_devices('GPU')\n# print(\"Available GPUs:\", [gpu.name for gpu in gpus])  # Should list two T4 GPUs\n# for gpu in gpus:\n#     tf.config.experimental.set_memory_growth(gpu, True)\n\n\n\n# Initialize MirroredStrategy\nstrategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\nprint(\"Number of GPUs in strategy:\", strategy.num_replicas_in_sync)  # Should print 2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:40:12.249501Z","iopub.execute_input":"2025-07-15T02:40:12.249790Z","iopub.status.idle":"2025-07-15T02:40:26.779315Z","shell.execute_reply.started":"2025-07-15T02:40:12.249717Z","shell.execute_reply":"2025-07-15T02:40:26.778519Z"}},"outputs":[{"name":"stderr","text":"2025-07-15 02:40:13.800559: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752547213.996967      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752547214.056576      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Number of GPUs in strategy: 2\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752547226.742760      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"IMG_SIZE = (112, 112)\nBATCH_SIZE = 128\nEPOCHS = 20\n\ndata_dir = \"/kaggle/input/11-785-fall-20-homework-2-part-2\"\npairs_file = os.path.join(data_dir, \"verification_pairs_val.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:40:26.781171Z","iopub.execute_input":"2025-07-15T02:40:26.781659Z","iopub.status.idle":"2025-07-15T02:40:26.785916Z","shell.execute_reply.started":"2025-07-15T02:40:26.781639Z","shell.execute_reply":"2025-07-15T02:40:26.785123Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\ndef create_data_generators(data_dir):\n\n\n    # Define data augmentation for training\n    train_datagen = ImageDataGenerator(\n      \n        zoom_range = 0.3,\n        shear_range = 0.2,        \n        fill_mode=\"nearest\",\n        horizontal_flip=True\n    )\n\n    # Define validation data generator (no augmentation, only rescaling)\n    val_datagen = ImageDataGenerator()\n\n    # Classification data generator for training\n    train_generator = train_datagen.flow_from_directory(\n        os.path.join(data_dir, 'classification_data/train_data'),\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        color_mode = 'rgb',\n        class_mode='categorical',\n        shuffle = True \n    )\n\n    # Classification data generator for validation\n    val_generator = val_datagen.flow_from_directory(\n        os.path.join(data_dir, 'classification_data/val_data'),\n        target_size=IMG_SIZE,\n        color_mode = 'rgb',\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle = False\n    )\n\n    \n\n    # Return datasets and number of classes\n    return train_generator, val_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:40:26.786612Z","iopub.execute_input":"2025-07-15T02:40:26.786972Z","iopub.status.idle":"2025-07-15T02:40:27.020456Z","shell.execute_reply.started":"2025-07-15T02:40:26.786952Z","shell.execute_reply":"2025-07-15T02:40:27.019601Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\ntrain_dataset, val_dataset = create_data_generators(data_dir)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:40:27.021586Z","iopub.execute_input":"2025-07-15T02:40:27.021843Z","iopub.status.idle":"2025-07-15T02:43:47.427997Z","shell.execute_reply.started":"2025-07-15T02:40:27.021821Z","shell.execute_reply":"2025-07-15T02:43:47.427447Z"}},"outputs":[{"name":"stdout","text":"Found 380638 images belonging to 4000 classes.\nFound 8000 images belonging to 4000 classes.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def create_verification_generator(data_dir, pairs_file):\n    df = pd.read_csv(pairs_file, sep='\\s+', names=['img1', 'img2', 'label'])\n    \n    def generator():\n        for _, row in df.iterrows():\n            img1 = cv2.imread(os.path.join(data_dir, row['img1']))\n            img2 = cv2.imread(os.path.join(data_dir, row['img2']))\n            img1 = cv2.resize(img1, IMG_SIZE) / 255.0  # Hardcode the size\n            img2 = cv2.resize(img2, IMG_SIZE) / 255.0\n            yield [img1, img2], row['label']\n    \n    # Use output_signature instead of output_types/output_shapes\n    dataset = tf.data.Dataset.from_generator(\n        generator,\n        output_signature=(\n            (tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), dtype=tf.float32),\n             tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), dtype=tf.float32)),\n            tf.TensorSpec(shape=(), dtype=tf.float32)\n        )\n    )\n    \n    return dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:43:47.428728Z","iopub.execute_input":"2025-07-15T02:43:47.428971Z","iopub.status.idle":"2025-07-15T02:43:47.434927Z","shell.execute_reply.started":"2025-07-15T02:43:47.428953Z","shell.execute_reply":"2025-07-15T02:43:47.434243Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"verification_dataset = create_verification_generator(data_dir, pairs_file)\nprint(len(train_dataset.class_indices))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:43:47.435532Z","iopub.execute_input":"2025-07-15T02:43:47.435719Z","iopub.status.idle":"2025-07-15T02:43:47.555537Z","shell.execute_reply.started":"2025-07-15T02:43:47.435696Z","shell.execute_reply":"2025-07-15T02:43:47.554913Z"}},"outputs":[{"name":"stdout","text":"4000\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def create_siamese_network(input_shape =(*IMG_SIZE, 3)):\n    base_model = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = input_shape)\n\n    for layer in base_model.layers:\n        layer.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128, activation = None, name = 'embedding')(x)\n    base_network = Model(inputs = base_model.input, outputs = x)\n    input_a = Input(shape = input_shape)\n    input_b = Input(shape = input_shape)\n\n    embedding_a = base_network(input_a)\n    embedding_b = base_network(input_b)\n\n    # Calculate Euclidean distance\n    distance = Lambda(lambda tensors: tf.sqrt(tf.reduce_sum(tf.square(tensors[0] - tensors[1]), axis=1, keepdims=True)))([embedding_a, embedding_b])\n    \n    # Create Siamese model\n    siamese_model = Model(inputs=[input_a, input_b], outputs=distance)\n    \n    return siamese_model, base_network\n\n\ndef create_classification_model(num_classes, input_shape =(*IMG_SIZE, 3)):\n    base_model = EfficientNetV2B0(weights = 'imagenet', include_top = False, input_shape= input_shape)\n    base_model.trainable = True\n\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    \n    x = Dense(128)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.4)(x)\n    \n    output = Dense(num_classes, activation = 'softmax')(x)\n\n    model = Model(inputs = base_model.input, outputs = output)\n    return model, base_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:43:47.557641Z","iopub.execute_input":"2025-07-15T02:43:47.558040Z","iopub.status.idle":"2025-07-15T02:43:47.564242Z","shell.execute_reply.started":"2025-07-15T02:43:47.558022Z","shell.execute_reply":"2025-07-15T02:43:47.563534Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def create_callbacks(model_name):\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_accuracy',\n        factor=0.1,\n        patience=4,\n        min_lr=1e-6,\n        verbose=1\n    )\n    \n    early_stopping = EarlyStopping(\n        monitor='val_accuracy',\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    )\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    checkpoint = ModelCheckpoint(\n        f'best_{model_name}_model_{timestamp}.keras',\n        monitor='val_accuracy',\n        save_best_only=True,\n        mode= 'auto',\n        verbose=1\n    )\n    \n    return [reduce_lr, early_stopping, checkpoint]\n    \ndef train_classification_model(pretrained_model_path=None, initial_epoch=0, phase=None):\n\n    classification_model, base_model = create_classification_model(\n        len(train_dataset.class_indices), (*IMG_SIZE, 3)\n    )\n    \n    # If you have a pretrained model, load weights instead\n    if pretrained_model_path:\n        classification_model = load_model(pretrained_model_path)\n    \n    # Compile\n    classification_model.compile(\n        optimizer=Adam(learning_rate=0.0001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    classification_callbacks = create_callbacks(\"EfficientNetV2B0_classification\")\n    history_phase1 = None\n    if phase in [1, None]:\n        # Phase 1: Frozen base model training\n        history_phase1 = classification_model.fit(\n            train_dataset,\n            validation_data=val_dataset,\n            epochs=EPOCHS,\n            initial_epoch=initial_epoch,\n            verbose=1,\n            callbacks=classification_callbacks\n        )\n\n    # Phase 2: Fine-tuning\n    for layer in classification_model.layers:\n        layer.trainable = True\n    print(f\"Unfroze base model: {base_model.name}\")\n    fine_tune_epoch = initial_epoch if phase == 2 else EPOCHS\n\n    \n    \n    classification_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    # Fine-tuning phase\n    history_phase2 = classification_model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=150,\n        initial_epoch=fine_tune_epoch,\n        verbose=1,\n        callbacks=create_callbacks(\"classification_finetuned\")\n    )\n\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    print(f\"Saving model at {timestamp}\")\n    classification_model.save(f\"custom_model_{timestamp}.keras\")\n    df = pd.DataFrame(history_phase2.history)\n    df.to_csv(f\"custom_model_loss_{timestamp}.csv\")\n\n    return classification_model, history_phase1, history_phase2\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:43:47.564991Z","iopub.execute_input":"2025-07-15T02:43:47.565194Z","iopub.status.idle":"2025-07-15T02:43:47.585973Z","shell.execute_reply.started":"2025-07-15T02:43:47.565176Z","shell.execute_reply":"2025-07-15T02:43:47.585333Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def contrastive_loss(y_true, y_pred):\n    \"\"\"Simple contrastive loss for Siamese network.\"\"\"\n    margin = 1.0\n    square_pred = tf.square(y_pred)\n    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n\ndef train_siamese_model(model=None, base_model=None, initial_epoch=0, phase=None):\n    global strategy  # Use the global MirroredStrategy from Step 1\n\n    \n    if model is None:\n        siamese_model, base_network = create_siamese_network((*IMG_SIZE, 3))\n    else:\n        siamese_model = model\n        base_network = base_model if base_model else siamese_model.get_layer('model')  # Extract base network\n\n    # Compile model\n    siamese_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4, weight_decay=1e-4),\n        loss=contrastive_loss,\n        metrics=['accuracy']\n    )\n\n    siamese_callbacks = create_callbacks(\"siamese\")\n    history_phase1 = None\n    if phase in [None, 1]:\n        print(\"=== Phase 1: Training Siamese Model (Frozen Base) ===\")\n        history_phase1 = siamese_model.fit(\n            verification_dataset,\n            validation_data=verification_dataset,  # Replace with actual validation dataset if available\n            epochs=EPOCHS,\n            initial_epoch=initial_epoch,\n            verbose=1,\n            callbacks=siamese_callbacks\n        )\n\n    # Phase 2: Fine-tuning\n    for layer in base_network.layers:\n        layer.trainable = True\n        print(f\"Unfroze layer: {layer.name}\")\n\n    # Recompile with lower learning rate\n    \n    siamese_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n        loss=contrastive_loss,\n        metrics=['accuracy']\n    )\n\n    \n    history_phase2 = siamese_model.fit(\n        verification_dataset,\n        validation_data=verification_dataset,  # Replace with actual validation dataset if available\n        epochs=EPOCHS,\n        initial_epoch=initial_epoch if phase == 1 else EPOCHS,\n        verbose=1,\n        callbacks=create_callbacks(\"siamese_finetuned\")\n    )\n\n    print(\"Saving model\")\n    siamese_model.save(\"custom_model_siamese.keras\")\n    df = pd.DataFrame(history_phase2.history)\n    df.to_csv(\"custom_model_siamese_loss.csv\")\n\n    return siamese_model, base_network, history_phase1, history_phase2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:43:47.586768Z","iopub.execute_input":"2025-07-15T02:43:47.587017Z","iopub.status.idle":"2025-07-15T02:43:47.605665Z","shell.execute_reply.started":"2025-07-15T02:43:47.587000Z","shell.execute_reply":"2025-07-15T02:43:47.605028Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def evaluate_model(siamese_model, verification_dataset):\n    predictions = []\n    true_labels = []\n\n    for (img1, img2), label in verification_dataset:\n        pred = siamese_model.predict([img1, img2], verbose=0)\n        predictions.extend(pred.flatten())\n        true_labels.extend(label.numpy())\n\n    fpr, tpr, _ = roc_curve(true_labels, predictions)\n    roc_auc = auc(fpr, tpr)\n\n    return fpr, tpr, roc_auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:43:47.606374Z","iopub.execute_input":"2025-07-15T02:43:47.606586Z","iopub.status.idle":"2025-07-15T02:43:47.623804Z","shell.execute_reply.started":"2025-07-15T02:43:47.606571Z","shell.execute_reply":"2025-07-15T02:43:47.623220Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def main():\n    # Load or create classification model\n    classification_model, hist1, hist2 = train_classification_model(\n        pretrained_model_path=\"/kaggle/input/verfication_model/keras/default/6/best_classification_finetuned_model_20250714_060424 (1).keras\",\n        initial_epoch=109,\n        phase=2\n    )\n\n    # Train Siamese model\n    siamese_model, base_network, siamese_hist1, siamese_hist2 = train_siamese_model(\n        initial_epoch=0,\n        phase=None\n    )\n\n    # Evaluate Siamese model\n    verification_dataset = create_verification_generator(data_dir, pairs_file)\n    fpr, tpr, roc_auc = evaluate_model(siamese_model, verification_dataset)\n    print(f\"ROC AUC: {roc_auc}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T02:43:47.624536Z","iopub.execute_input":"2025-07-15T02:43:47.624805Z","iopub.status.idle":"2025-07-15T06:28:41.371602Z","shell.execute_reply.started":"2025-07-15T02:43:47.624781Z","shell.execute_reply":"2025-07-15T06:28:41.370250Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\nUnfroze base model: efficientnetv2-b0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 110/150\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1752547502.141103      87 service.cc:148] XLA service 0x7be344001ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1752547502.141895      87 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1752547507.871241      87 cuda_dnn.cc:529] Loaded cuDNN version 90300\nE0000 00:00:1752547517.584517      87 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752547517.774593      87 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752547518.318083      87 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752547518.531757      87 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/2974\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m83:54:48\u001b[0m 102s/step - accuracy: 0.8359 - loss: 0.5068","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752547539.855700      87 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1453/2974\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m18:30\u001b[0m 730ms/step - accuracy: 0.8170 - loss: 0.7004","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1752548613.229134      88 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752548613.414465      88 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752548613.913512      88 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1752548614.122906      88 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783ms/step - accuracy: 0.8158 - loss: 0.7058\nEpoch 110: val_accuracy improved from -inf to 0.73563, saving model to best_classification_finetuned_model_20250715_024356.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2474s\u001b[0m 798ms/step - accuracy: 0.8158 - loss: 0.7058 - val_accuracy: 0.7356 - val_loss: 1.4987 - learning_rate: 1.0000e-04\nEpoch 111/150\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.8187 - loss: 0.6894\nEpoch 111: val_accuracy did not improve from 0.73563\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1796s\u001b[0m 604ms/step - accuracy: 0.8187 - loss: 0.6894 - val_accuracy: 0.7344 - val_loss: 1.5318 - learning_rate: 1.0000e-04\nEpoch 112/150\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616ms/step - accuracy: 0.8223 - loss: 0.6775\nEpoch 112: val_accuracy improved from 0.73563 to 0.74187, saving model to best_classification_finetuned_model_20250715_024356.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1852s\u001b[0m 623ms/step - accuracy: 0.8223 - loss: 0.6775 - val_accuracy: 0.7419 - val_loss: 1.4865 - learning_rate: 1.0000e-04\nEpoch 113/150\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647ms/step - accuracy: 0.8221 - loss: 0.6758\nEpoch 113: val_accuracy did not improve from 0.74187\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1944s\u001b[0m 654ms/step - accuracy: 0.8221 - loss: 0.6758 - val_accuracy: 0.7389 - val_loss: 1.5004 - learning_rate: 1.0000e-04\nEpoch 114/150\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - accuracy: 0.8245 - loss: 0.6690\nEpoch 114: val_accuracy did not improve from 0.74187\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1933s\u001b[0m 650ms/step - accuracy: 0.8245 - loss: 0.6690 - val_accuracy: 0.7395 - val_loss: 1.5297 - learning_rate: 1.0000e-04\nEpoch 115/150\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - accuracy: 0.8251 - loss: 0.6612\nEpoch 115: val_accuracy improved from 0.74187 to 0.74287, saving model to best_classification_finetuned_model_20250715_024356.keras\n\u001b[1m2974/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1991s\u001b[0m 670ms/step - accuracy: 0.8251 - loss: 0.6612 - val_accuracy: 0.7429 - val_loss: 1.5176 - learning_rate: 1.0000e-04\nEpoch 116/150\n\u001b[1m2225/2974\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m8:22\u001b[0m 670ms/step - accuracy: 0.8282 - loss: 0.6497","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1078702804.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/1078702804.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load or create classification model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     classification_model, hist1, hist2 = train_classification_model(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mpretrained_model_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/input/verfication_model/keras/default/6/best_classification_finetuned_model_20250714_060424 (1).keras\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m109\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3753117605.py\u001b[0m in \u001b[0;36mtrain_classification_model\u001b[0;34m(pretrained_model_path, initial_epoch, phase)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Fine-tuning phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     history_phase2 = classification_model.fit(\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":11}]}